{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "from random import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repos_name(user_data_repos):\n",
    "    repos = []\n",
    "    description=[]\n",
    "    for i in range(len(user_data_repos)):\n",
    "        \n",
    "        if user_data_repos[i]['name'] not in repos_test:\n",
    "            repos.append(user_data_repos[i]['name'])\n",
    "            \n",
    "            if user_data_repos[i]['description'] is not None:\n",
    "                description.append(user_data_repos[i]['description'])\n",
    "            else:\n",
    "                description.append(user_data_repos[i]['name'])\n",
    "        \n",
    "        else:\n",
    "            print(user_data_repos[i]['name'])\n",
    "    \n",
    "    return repos,description\n",
    "\n",
    "def fetch_contributor(name, repo):\n",
    "    name='/'+name\n",
    "    repo='/'+repo\n",
    "    url_contributor = 'https://api.github.com/repos'+name+repo+'/contributors'\n",
    "    requestObj_con = requests.get(url = url_contributor, headers=headers)\n",
    "    user_data_con = requestObj_con.json()\n",
    "\n",
    "    if type(user_data_con) == list:\n",
    "        user_data = user_data_con\n",
    "        ids = []\n",
    "        num_cons = []\n",
    "        names = []\n",
    "        for i in np.arange(0,len(user_data)):\n",
    "            ids.append(user_data[i]['id'])\n",
    "            num_cons.append(user_data[i]['contributions'])\n",
    "            names.append(user_data[i]['login'])\n",
    "    else:\n",
    "        ids=None\n",
    "        num_cons=None\n",
    "        names=None\n",
    "    return ids, num_cons, names\n",
    "\n",
    "def fetch_committer(user_data):\n",
    "    list_committer = []\n",
    "    for i in np.arange(0,len(user_data)):\n",
    "        if user_data[i]['committer'] is not None:\n",
    "            list_committer.append(user_data[i]['committer']['id'])\n",
    "        else:\n",
    "            list_committer.append(0)\n",
    "    return list_committer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input a person' name, output this person' all repos\n",
    "def all_repos(name):\n",
    "    name='/'+name\n",
    "    url_owner ='https://api.github.com/users'+name\n",
    "    headers = {'Authorization':'token e392138bc68d0d084dffb5da033d07168b7eafeb'}\n",
    "    requestObj_owner = requests.get(url = url_owner, headers=headers)\n",
    "    user_data_owner = requestObj_owner.json()\n",
    "    url_repos = user_data_owner['repos_url']\n",
    "    owner_id = user_data_owner['id']\n",
    "    owner_name = user_data_owner['login']\n",
    "    requestObj_repos = requests.get(url = url_repos, headers=headers)\n",
    "    user_data_repos = requestObj_repos.json()\n",
    "    repos,descriptions = repos_name(user_data_repos)\n",
    "    return repos,descriptions\n",
    "\n",
    "# combine repos and their descriptions\n",
    "def repos_desc(repos, descriptions):\n",
    "    repos_string=[]\n",
    "    for i in range(len(repos)):\n",
    "        if descriptions[i] is not None:\n",
    "            string_temp = repos[i]+' '+descriptions[i]\n",
    "        else:\n",
    "            string_temp = repos[i]\n",
    "        repos_string.append(string_temp)\n",
    "    return repos_string\n",
    "\n",
    "def network(name):\n",
    "    repos, descriptions = all_repos(name)\n",
    "    num = len(repos)\n",
    "    # print(repos)\n",
    "    edge = {'source':[],'target':[],'weight':[]}\n",
    "    node = {'id':[],'label':[]}\n",
    "    url_owner ='https://api.github.com/users'+'/'+name\n",
    "    headers = {'Authorization':'token e392138bc68d0d084dffb5da033d07168b7eafeb'}\n",
    "    requestObj_owner = requests.get(url = url_owner, headers=headers)\n",
    "    user_data_owner = requestObj_owner.json()\n",
    "    owner_id = user_data_owner['id']\n",
    "    owner_name = user_data_owner['login']\n",
    "    node['id'].append(owner_id)\n",
    "    node['label'].append(owner_name)\n",
    "    \n",
    "    for repo in repos:\n",
    "        #repo = '/'+repo   \n",
    "        url_commit = 'https://api.github.com/repos'+'/'+name+'/'+repo+'/commits'\n",
    "        requestObj_com = requests.get(url = url_commit, headers=headers)\n",
    "        user_data_com = requestObj_com.json()\n",
    "        if type(user_data_com) != dict:\n",
    "            ids, num_cons, names = fetch_contributor(name, repo)\n",
    "            weight_cons = np.array(num_cons)    \n",
    "            sum_weight_cons = sum(weight_cons)\n",
    "            weight_cons = weight_cons/sum_weight_cons\n",
    "            weight_cons = np.round(weight_cons,3)\n",
    "            for i in range(len(ids)):\n",
    "                edge['source'].append(owner_id)\n",
    "                edge['target'].append(ids[i])\n",
    "                edge['weight'].append(weight_cons[i])\n",
    "                if ids[i] not in node['id']:\n",
    "                    node['id'].append(ids[i])\n",
    "                    node['label'].append(names[i])\n",
    "    name_list_string = [name]*num\n",
    "    repos_string={}\n",
    "    repos_string['repos']=repos\n",
    "    repos_string['descriptions']=descriptions\n",
    "    repos_string['name_list']=[name]*num # who fork this repo\n",
    "    return num, repos, repos_string, edge, node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge 2 dicts with the same keys\n",
    "def merge_dict(df1,df2):\n",
    "    df={}\n",
    "    for key in df1.keys():\n",
    "        df[key] = df1[key]+df2[key]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "'''\n",
    "network = pd.DataFrame(edge_total)\n",
    "network.to_csv('net_han.csv',index=False)\n",
    "\n",
    "network_node=pd.DataFrame(node_total)\n",
    "network_node.drop_duplicates(['id','label'],keep='first',inplace=True)\n",
    "network_node.to_csv('net_node_han.csv',index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SequenceMatcher:\n",
    "The idea is to find the longest contiguous matching subsequence that contains no “junk” elements; these “junk” elements are ones that are uninteresting in some sense, such as blank lines or whitespace.\n",
    "#### The Levenshtein distance:\n",
    "The Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions, or substitutions) required to change one word into the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math\n",
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein as lev\n",
    "import difflib\n",
    "import statistics\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "def cos_sim(s1, s2):\n",
    "    s1=s1.lower()\n",
    "    s2=s2.lower()\n",
    "    vector1 = text_to_vector(s1)\n",
    "    vector2 = text_to_vector(s2)\n",
    "    cosine = get_cosine(vector1, vector2)\n",
    "    return cosine\n",
    "\n",
    "def string_similar(s1, s2):\n",
    "    return difflib.SequenceMatcher(None, s1, s2).quick_ratio()\n",
    "\n",
    "def similarity(s1,s2):\n",
    "    s1=s1.lower()\n",
    "    s2=s2.lower()\n",
    "    cosine = cos_sim(s1,s2)\n",
    "    Ratio = fuzz.ratio(s1.lower(),s2.lower())\n",
    "    ratio = np.round(Ratio/100,2)\n",
    "    Distance = lev.distance(s1.lower(),s2.lower())\n",
    "    dis = np.round(1-Distance/max(len(s1),len(s2)),2)\n",
    "    SeqMatch = string_similar(s1,s2)\n",
    "    sim = [cosine, SeqMatch, ratio, dis]\n",
    "    mean_sim = statistics.mean(sim)\n",
    "    return mean_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity test for peport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1='GitHub API Python'\n",
    "t2='GitHub_API_Python'\n",
    "t3='GitHub-API-Python'\n",
    "t4='GITHUB-API-PYTHON'\n",
    "t5='Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 0.88 0.88 0.35 0.35\n"
     ]
    }
   ],
   "source": [
    "s1 = lev.distance(t1,t2)\n",
    "s2 = lev.distance(t1.lower(),t2.lower())\n",
    "s3 = lev.distance(t1.lower(),t3.lower())\n",
    "s4 = lev.distance(t1,t4)\n",
    "s5 = lev.distance(t1.lower(),t5.lower())\n",
    "s1 = np.round(1-s1/max(len(t1),len(t2)),2)\n",
    "s2 = np.round(1-s2/max(len(t1),len(t2)),2)\n",
    "s3 = np.round(1-s3/max(len(t1),len(t3)),2)\n",
    "s4 = np.round(1-s4/max(len(t1),len(t4)),2)\n",
    "s5 = np.round(1-s5/max(len(t1),len(t5)),2)\n",
    "print(s1,s2,s3,s4,s5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706 0.8823529411764706 0.5294117647058824 0.65\n"
     ]
    }
   ],
   "source": [
    "s1=string_similar(t1, t2)\n",
    "s2=string_similar(t1, t3)\n",
    "s3=string_similar(t1, t4)\n",
    "s4=string_similar(t1, t5)\n",
    "print(s1,s2,s3,s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0000000000000002 0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "s1=cos_sim(t1, t2)\n",
    "s2=cos_sim(t1, t3)\n",
    "s3=cos_sim(t1, t5)\n",
    "print(s1,s2,s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_cal(num_con):   \n",
    "    weight_con = np.array(num_con)    \n",
    "    sum_weight_con = sum(weight_con)\n",
    "    weight_con = weight_con/sum_weight_con\n",
    "    weight_con = np.round(weight_con,3)\n",
    "    return weight_con.tolist()\n",
    "\n",
    "def list_multiply(List1,List2):\n",
    "    List = np.multiply(np.array(List1),np.array(List2))\n",
    "    return List.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def similarit_list(repo_new, developer_name):\n",
    "    num, repos, repos_string, edge, node=network(developer_name) \n",
    "\n",
    "    sim = []\n",
    "    s1 = repo_new\n",
    "    for j in range(num):\n",
    "        s2 = repos[j]\n",
    "        sim.append(similarity(s1,s2))\n",
    "    return sim, repos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repos and descriptions used to evaluate the model\n",
    "\n",
    "a='ai_law' \n",
    "a_d='all kinds of baseline models for long text classificaiton( text categorization)'\n",
    "\n",
    "b='fashion-recommendation' \n",
    "b_d='A clothing retrieval and visual recommendation model for fashion images'\n",
    "\n",
    "c='aspnet-core-social-network'\n",
    "c_d='aspnet-core-social-network'\n",
    "\n",
    "d='Bitbucket-Api'\n",
    "d_d='Bitbucket-Api'\n",
    "\n",
    "e='FDTKit'\n",
    "e_d='FDTKit is a fuzzy decision tree toolkit includes the state of art fuzzy decision tree algorithms'\n",
    "\n",
    "repos_test = [a,b,c,d,e]\n",
    "desc_test =[a_d, b_d, c_d, d_d, e_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1-layer social network - hanwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "num0, repos0, repos_string0, edge0, node0=network('hanwang921017')\n",
    "# save data\n",
    "network0 = pd.DataFrame(edge0)\n",
    "network0.to_csv('net_han0_e.csv',index=False)\n",
    "\n",
    "network_node0=pd.DataFrame(node0)\n",
    "network_node0.drop_duplicates(['id','label'],keep='first',inplace=True)\n",
    "network_node0.to_csv('net_node_han0_e.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collaborative-Filtering-for-Implicit-Feedback-Datasets', 'Fuzzy_Decision_Tree', 'gitdemo', 'github-api-examples', 'Movie-Recommendation', 'movielens', 'open-social-network', 'RecommenderSystems', 'StackOverfFlow_API', 'StackOverflow-API', 'StackOverflow_Q-A', 'text_classification']\n"
     ]
    }
   ],
   "source": [
    "print(repos0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-layer social network - hanwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDTKit\n",
      "fashion-recommendation\n",
      "aspnet-core-social-network\n",
      "Bitbucket-Api\n",
      "ai_law\n"
     ]
    }
   ],
   "source": [
    "name_0 = 'hanwang921017'\n",
    "#repo_new = 'movie recommendation python'\n",
    "\n",
    "num, repos, repos_string_total,edge_total, node_total=network(name_0)\n",
    "for repo in repos:\n",
    "    con_ids, num_cons, con_names = fetch_contributor(name_0,repo)\n",
    "    for name in con_names:\n",
    "        num, repos, repos_string, edge, node=network(name) \n",
    "        edge_total = merge_dict(edge_total, edge)\n",
    "        node_total = merge_dict(node_total, node)\n",
    "        repos_string_total = merge_dict(repos_string_total,repos_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "repos_string_total_new={}\n",
    "for key in repos_string_total.keys():\n",
    "    repos_string_total_new[key]=[]\n",
    "\n",
    "for i in range(len(repos_string_total['repos'])):\n",
    "    repo_new = repos_string_total['repos'][i]\n",
    "    if repo_new not in repos_string_total_new['repos']:\n",
    "        for key in repos_string_total.keys():\n",
    "            repos_string_total_new[key].append(repos_string_total[key][i])\n",
    "        \n",
    "print(len(repos_string_total_new['repos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2877\n"
     ]
    }
   ],
   "source": [
    "print(type(node_total))\n",
    "print(len(node_total['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(repos_string_total['repos']))\n",
    "for rp in repos_test:\n",
    "    print(rp in repos_string_total['repos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "network = pd.DataFrame(edge_total)\n",
    "network.to_csv('net_han_e.csv',index=False)\n",
    "\n",
    "network_node=pd.DataFrame(node_total)\n",
    "network_node.drop_duplicates(['id','label'],keep='first',inplace=True)\n",
    "network_node.to_csv('net_node_han_e.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repos used to evaluate the model\n",
    "\n",
    "authors=['brightmart','khanhnamle1994','Qolzam','RookieOne','mhjabreel']\n",
    "\n",
    "a='ai_law' \n",
    "a_d='all kinds of baseline models for long text classificaiton( text categorization)'\n",
    "a2 = 'Hierarchical-Text-Multi-Label-Classificaiton'\n",
    "a2_d='About Hierarchical Muti-Label Text Classification based on hybrid method (local & global)'\n",
    "\n",
    "\n",
    "b='fashion-recommendation' \n",
    "b_d='A clothing retrieval and visual recommendation model for fashion images'\n",
    "b2='movie-recommendation-system'\n",
    "b2_d='A movie recommendation system given by user data, movie data and social data'\n",
    "\n",
    "\n",
    "c='aspnet-core-social-network'\n",
    "c_d='aspnet-core-social-network'\n",
    "c2='react-social-network'\n",
    "c2_d='Simple React Social Network'\n",
    "\n",
    "d='Bitbucket-Api'\n",
    "d_d='Bitbucket-Api'\n",
    "d2='Minature-Stackoverflow-APIs'\n",
    "d2_d='The project is containing all the existing features of Stack Overflow and with some additional features and also give connection to the AWS services'\n",
    "\n",
    "e='FDTKit'\n",
    "e_d='FDTKit is a fuzzy decision tree toolkit includes the state of art fuzzy decision tree algorithms'\n",
    "e2='fuzzyLilly'\n",
    "e2_d='A wrapper to create fuzzy decision trees for more accurate fuzzy predictions'\n",
    "\n",
    "repos_test = [a,a2,b,b2,c,c2,d,d2,e,e2]\n",
    "desc_test =[a_d,a2_d,b_d,b2_d,c_d,c2_d,d_d,d2_d,e_d,e2_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_contributor = 'https://api.github.com/repos'+'/'+'AbdulAli'+'/'+'AbdulAli'+'/commits'\n",
    "requestObj_con0 = requests.get(url = url_contributor, headers=headers)\n",
    "user_data_con = requestObj_con0.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "def top_k(num):\n",
    "    \n",
    "    #repo_new='StackOverfFlow API with Python'\n",
    "    winner_list=[]\n",
    "    for repo_i in range(len(repos_test)):\n",
    "        [repo_new,repo_desc]=[repos_test[repo_i],desc_test[repo_i]]\n",
    "        s1 = repo_new\n",
    "        s1_d = repo_desc\n",
    "        sim_list=[]\n",
    "        for s2,s2_d in zip(repos_string_total['repos'],repos_string_total_new['descriptions']):\n",
    "            a_temp = np.round(similarity(s1,s2),5) # similarity(new title, title)\n",
    "            a_temp = np.round(similarity(s1_d,s2),5) + a_temp # similarity(new decs, title)\n",
    "            b_temp = np.round(similarity(s1_d,s2_d),5) # similarity(new desc, desc)\n",
    "            b_temp = np.round(similarity(s1,s2_d),5) + b_temp # similarity(new title, desc)\n",
    "\n",
    "            sim_list.append(a_temp+b_temp)# sum similarity between titles and descs\n",
    "        #print('length of similarity list:',len(sim_list))\n",
    "        '''\n",
    "        n=copy.copy(num)\n",
    "        m=copy.copy(num) # number of condidate developers recommended\n",
    "        while True:    \n",
    "            index_n = heapq.nlargest(n, sim_list)\n",
    "            index_n =- np.sort(-np.unique(index_n))\n",
    "            if len(index_n)<m:\n",
    "                n=n+1\n",
    "            else:\n",
    "                break\n",
    "        '''\n",
    "        m=20\n",
    "        index_n = heapq.nlargest(m, sim_list)\n",
    "        condidate={'name_fork':[],'repo':[],'description':[],'similarity':[],\n",
    "                   'id_contributor':[],'name_contributor':[],'weight':[],'score':[]}\n",
    "\n",
    "        for i in range(m):\n",
    "            max_i = sim_list.index(index_n[i])\n",
    "\n",
    "            name = repos_string_total_new['name_list'][max_i]\n",
    "\n",
    "            repo = repos_string_total_new['repos'][max_i]\n",
    "\n",
    "            desc = repos_string_total_new['descriptions'][max_i]\n",
    "\n",
    "            url_contributor = 'https://api.github.com/repos'+'/'+name+'/'+repo+'/commits'\n",
    "            requestObj_con0 = requests.get(url = url_contributor, headers=headers)\n",
    "            user_data_con = requestObj_con0.json()\n",
    "\n",
    "            if type(user_data_con) == list:\n",
    "\n",
    "                ids_con, num_con, name_con = fetch_contributor(name, repo)\n",
    "\n",
    "                weight_con = weight_cal(num_con)\n",
    "\n",
    "                condidate['id_contributor']=condidate['id_contributor']+ids_con\n",
    "                condidate['name_contributor']=condidate['name_contributor']+name_con\n",
    "\n",
    "                condidate['weight']=condidate['weight']+weight_con\n",
    "\n",
    "                num_contributor = len(name_con)\n",
    "\n",
    "                condidate['name_fork'] = condidate['name_fork']+[name]*num_contributor\n",
    "                condidate['repo']=condidate['repo']+[repo]*num_contributor\n",
    "                condidate['description']=condidate['description']+[desc]*num_contributor\n",
    "                condidate['similarity']=condidate['similarity']+[index_n[i]]*num_contributor\n",
    "\n",
    "        condidate['score'] = list_multiply(condidate['similarity'],condidate['weight'])    \n",
    "        #print(condidate)\n",
    "        \n",
    "        # merge same contributors\n",
    "        condidate_new={'name_fork':[],'repo':[],'description':[],'similarity':[],\n",
    "           'id_contributor':[],'name_contributor':[],'weight':[],'score':[]}\n",
    "\n",
    "        for i in range(len(condidate['score'])):\n",
    "            if condidate['id_contributor'][i] not in condidate_new['id_contributor']:\n",
    "                for key in condidate.keys():\n",
    "                    condidate_new[key].append(condidate[key][i])\n",
    "            else:\n",
    "                rep_ind=condidate_new['id_contributor'].index(condidate['id_contributor'][i])\n",
    "                condidate_new['score'][rep_ind]=condidate_new['score'][rep_ind]+condidate['score'][i]\n",
    "            \n",
    "\n",
    "        #print(condidate['score'])\n",
    "        score = condidate_new['score']\n",
    "        '''\n",
    "        n=copy.copy(num)\n",
    "        m=copy.copy(num) # number of final developers recommended\n",
    "        while True:    \n",
    "            index_n = heapq.nlargest(n, score)\n",
    "            index_n =- np.sort(-np.unique(index_n))\n",
    "            if len(index_n)<m:\n",
    "                n=n+1\n",
    "            else:\n",
    "                break\n",
    "        '''\n",
    "        \n",
    "        index_n = heapq.nlargest(num, score)\n",
    "        #print(index_n)\n",
    "        max_list=[] # positions of maximum\n",
    "        for i in range(num):\n",
    "            max_i = score.index(index_n[i])\n",
    "            max_list.append(max_i)\n",
    "        #print(max_list)\n",
    "\n",
    "        winner ={'name_fork':[],'repo':[],'description':[],'similarity':[],\n",
    "                   'id_contributor':[],'name_contributor':[],'weight':[],'score':[]}\n",
    "        for i in max_list:\n",
    "            for key in winner.keys():\n",
    "                winner[key].extend([condidate_new[key][i]]) \n",
    "        winner_list.append(winner)\n",
    "        #print('\\nrepo_i:',repo_i)\n",
    "        #print('\\nwinner:\\n', winner)\n",
    "    #print(len(winner_list))\n",
    "\n",
    "    #accuracy\n",
    "    precision=0\n",
    "    for i in range(5):\n",
    "        author=authors[i]\n",
    "        for j in range(2):\n",
    "            if author in winner_list[2*i+j]['name_contributor']:\n",
    "                precision+=10\n",
    "            #else:print(2*i+j)\n",
    "    return precision/100,winner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "win = pd.DataFrame(a[1][0])\n",
    "win.to_csv('winner_TC_TOP5_1.csv')\n",
    "win = pd.DataFrame(a[1][1])\n",
    "win.to_csv('winner_TC_TOP5_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1,11)\n",
    "y=[]\n",
    "winner_top_k=[]\n",
    "for k in x:\n",
    "    p_temp, winner_list_temp=top_k(k)\n",
    "    y.append(p_temp)\n",
    "    winner_top_k.append(winner_list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the graph after get the top k precisions\n",
    "plt.plot(x,y,marker = '*',markersize='10')\n",
    "plt.xlabel('Top-k')\n",
    "plt.ylabel('Precision')\n",
    "plt.xticks(x, x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name_fork': ['hanwang921017'], 'repo': ['text_classification'], 'description': ['all kinds of text classification models and more with deep learning'], 'similarity': [1.06043], 'id_contributor': [19634224], 'name_contributor': ['brightmart'], 'weight': [0.963], 'score': [1.0385424]}\n",
      "{'name_fork': ['khanhnamle1994'], 'repo': ['android-basics'], 'description': ['A variety of applications built with Android Studio'], 'similarity': [1.5817], 'id_contributor': [10627238], 'name_contributor': ['khanhnamle1994'], 'weight': [1.0], 'score': [3.9760999999999997]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for j in range(10):\n",
    "        winner_top_k[i][j]['name_contributor']\n",
    "print(winner_top_k[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pd.DataFrame(winner_top_k[9][0])\n",
    "win.to_csv('winner_TC_TOP10_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "authors=['brightmart','khanhnamle1994','Qolzam','RookieOne','mhjabreel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test users:\n",
    "RookieOne: Stackoverflow API \n",
    "khanhnamle1994: movie recommendation\n",
    "Qolzam: social network\n",
    "mhjabreel: fuzzy decision tree\n",
    "brightmart: text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resources': {'core': {'limit': 5000, 'remaining': 5000, 'reset': 1575268531}, 'search': {'limit': 30, 'remaining': 30, 'reset': 1575264991}, 'graphql': {'limit': 5000, 'remaining': 5000, 'reset': 1575268531}, 'integration_manifest': {'limit': 5000, 'remaining': 5000, 'reset': 1575268531}}, 'rate': {'limit': 5000, 'remaining': 5000, 'reset': 1575268531}}\n"
     ]
    }
   ],
   "source": [
    "url_limit = 'https://api.github.com/rate_limit'\n",
    "headers = {'Authorization':  'token e392138bc68d0d084dffb5da033d07168b7eafeb'}\n",
    "\n",
    "requestObj_limit = requests.get(url = url_limit, headers=headers)\n",
    "user_data_limit = requestObj_limit.json()\n",
    "print(user_data_limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
